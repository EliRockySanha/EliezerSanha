{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76003bf2",
   "metadata": {},
   "source": [
    "#  PSO-SGD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbabc7e",
   "metadata": {},
   "source": [
    "## Com Modelos Sem Pré-Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ecafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        # model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        # model = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        # model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    elif architecture == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        # model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
    "    elif architecture == 'squeezenet':\n",
    "        model = models.squeezenet1_1(weights=None)\n",
    "        # model = models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "        model.num_classes = 10\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11', 'resnet18', 'mobilenet_v2' ou 'squeezenet'\")\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d95448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe Partícula para PSO adaptado ao treinamento da rede neural\n",
    "class Particle:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = copy.deepcopy(model).to(device)\n",
    "        self.best_model = copy.deepcopy(model).to(device)\n",
    "        # self.position = {name: torch.zeros_like(param).to(device) for name, param in model.named_parameters()}\n",
    "        # self.velocity = {name: torch.zeros_like(param).to(device) for name, param in model.named_parameters()}\n",
    "        \n",
    "        # Definir os limites do espaço de busca e a escala da velocidade\n",
    "        low = -10.0  # Limite inferior do espaço de busca\n",
    "        high = 10.0  # Limite superior do espaço de busca\n",
    "        velocity_scale = 0.1  # Escala para as velocidades iniciais\n",
    "        \n",
    "        # Inicializar a posição com valores aleatórios uniformes no intervalo [low, high]\n",
    "        self.position = {name: torch.rand_like(param).to(device) * (high - low) + low for name, param in model.named_parameters()}\n",
    "        \n",
    "        # Inicializar a velocidade com valores aleatórios pequenos (normalmente distribuídos)\n",
    "        self.velocity = {name: torch.randn_like(param).to(device) * velocity_scale for name, param in model.named_parameters()}\n",
    "\n",
    "        self.best_score = float('inf')\n",
    "        self.device = device\n",
    "        \n",
    "        # Inicializar o otimizador (por exemplo, Adam)\n",
    "        #self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "    def pso_sgd(self, global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, t):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            #if param.grad is None:\n",
    "                #continue\n",
    "\n",
    "            local_rand = random.random()\n",
    "            global_rand = random.random()\n",
    "\n",
    "            # Atualização da velocidade\n",
    "            self.velocity[name] = (\n",
    "                inertia * self.velocity[name]\n",
    "                + c1 * local_rand * (self.best_model.state_dict()[name].to(self.device) - param.data)\n",
    "                + c2 * global_rand * (global_best_model.state_dict()[name].to(self.device) - param.data)\n",
    "            )\n",
    "            \n",
    "            self.position[name] = param.data + self.velocity[name]\n",
    "            param.data = self.position[name]\n",
    "\n",
    "            # Move m[name] e v[name] para o mesmo dispositivo de param\n",
    "            m[name] = m[name].to(param.device)\n",
    "            v[name] = v[name].to(param.device)\n",
    "\n",
    "            # Verificar e Atualização do Adam\n",
    "            if param.grad is None:\n",
    "                m[name] = beta1 * m[name] + (1 - beta1) * param.grad\n",
    "                v[name] = beta2 * v[name] + (1 - beta2) * (param.grad ** 2)\n",
    "\n",
    "                m_hat = m[name] / (1 - beta1 ** t)\n",
    "                v_hat = v[name] / (1 - beta2 ** t)\n",
    "\n",
    "                # param.data = self.position[name] - learning_rate * m_hat / (torch.sqrt(v_hat) + epsilon)\n",
    "                param.data = self.position[name] - learning_rate * param.grad\n",
    "                # param.data = self.position[name] + learning_rate * param.grad\n",
    "                \n",
    "    def evaluate_test(self, dataloader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def evaluate_train(self, dataloader, criterion):\n",
    "        \"\"\"Calcula o erro (perda) e a acurácia da partícula utilizando o otimizador Adam.\"\"\"\n",
    "        self.model.train()  # Colocar o modelo em modo de treinamento\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Zerar gradientes acumulados\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(images)\n",
    "            \n",
    "            # Cálculo do erro (loss)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass (propagação do gradiente)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Atualizar os pesos usando Adam\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Acumular o erro total\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Cálculo da acurácia\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Obter predições (classe com maior probabilidade)\n",
    "            total += labels.size(0)                    # Número total de amostras\n",
    "            correct += (predicted == labels).sum().item()  # Número de predições corretas\n",
    "        \n",
    "        # Cálculo da perda média e acurácia\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total  # Acurácia = (predições corretas) / (total de amostras)\n",
    "\n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f610bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)    \n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size = 10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=10, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=10, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os hiperparâmetros do PSO e do Adam\n",
    "pop_size = 10\n",
    "num_epochs = 30\n",
    "#inertia = 0.9\n",
    "c1, c2 = 0.8, 0.9\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0d06b",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'alexnet'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    #Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdae07b",
   "metadata": {},
   "source": [
    "## MobileNet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'mobilenet_v2'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cd33a",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'resnet18'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df543a",
   "metadata": {},
   "source": [
    "## SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ff8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'squeezenet'  # escolha 'alexnet', 'vgg11', 'resnet18', 'mobilenet_v2' ou 'squeezenet'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "\n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "\n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "\n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c4434",
   "metadata": {},
   "source": [
    "## VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df04a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'vgg11'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b72b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

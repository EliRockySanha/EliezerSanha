{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76003bf2",
   "metadata": {},
   "source": [
    "#  PSO-SGD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbabc7e",
   "metadata": {},
   "source": [
    "## Com Modelos Sem Pré-Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924ecafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        # model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        # model = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        # model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    elif architecture == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        # model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
    "    elif architecture == 'squeezenet':\n",
    "        model = models.squeezenet1_1(weights=None)\n",
    "        # model = models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.IMAGENET1K_V1)\n",
    "        model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
    "        model.num_classes = 10\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11', 'resnet18', 'mobilenet_v2' ou 'squeezenet'\")\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d95448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe Partícula para PSO adaptado ao treinamento da rede neural\n",
    "class Particle:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = copy.deepcopy(model).to(device)\n",
    "        self.best_model = copy.deepcopy(model).to(device)\n",
    "        # self.position = {name: torch.zeros_like(param).to(device) for name, param in model.named_parameters()}\n",
    "        # self.velocity = {name: torch.zeros_like(param).to(device) for name, param in model.named_parameters()}\n",
    "        \n",
    "        # Definir os limites do espaço de busca e a escala da velocidade\n",
    "        low = -10.0  # Limite inferior do espaço de busca\n",
    "        high = 10.0  # Limite superior do espaço de busca\n",
    "        velocity_scale = 0.1  # Escala para as velocidades iniciais\n",
    "        \n",
    "        # Inicializar a posição com valores aleatórios uniformes no intervalo [low, high]\n",
    "        self.position = {name: torch.rand_like(param).to(device) * (high - low) + low for name, param in model.named_parameters()}\n",
    "        \n",
    "        # Inicializar a velocidade com valores aleatórios pequenos (normalmente distribuídos)\n",
    "        self.velocity = {name: torch.randn_like(param).to(device) * velocity_scale for name, param in model.named_parameters()}\n",
    "\n",
    "        self.best_score = float('inf')\n",
    "        self.device = device\n",
    "        \n",
    "        # Inicializar o otimizador (por exemplo, Adam)\n",
    "        #self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "    def pso_sgd(self, global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, t):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.grad is None:\n",
    "                continue\n",
    "\n",
    "            local_rand = random.random()\n",
    "            global_rand = random.random()\n",
    "\n",
    "            # Atualização da velocidade\n",
    "            self.velocity[name] = (\n",
    "                inertia * self.velocity[name]\n",
    "                + c1 * local_rand * (self.best_model.state_dict()[name].to(self.device) - param.data)\n",
    "                + c2 * global_rand * (global_best_model.state_dict()[name].to(self.device) - param.data)\n",
    "            )\n",
    "            \n",
    "            self.position[name] = param.data + self.velocity[name]\n",
    "            param.data = self.position[name]\n",
    "\n",
    "            # Move m[name] e v[name] para o mesmo dispositivo de param\n",
    "            m[name] = m[name].to(param.device)\n",
    "            v[name] = v[name].to(param.device)\n",
    "\n",
    "            # Atualização do Adam\n",
    "            m[name] = beta1 * m[name] + (1 - beta1) * param.grad\n",
    "            v[name] = beta2 * v[name] + (1 - beta2) * (param.grad ** 2)\n",
    "\n",
    "            m_hat = m[name] / (1 - beta1 ** t)\n",
    "            v_hat = v[name] / (1 - beta2 ** t)\n",
    "\n",
    "            # param.data = self.position[name] - learning_rate * m_hat / (torch.sqrt(v_hat) + epsilon)\n",
    "            param.data = self.position[name] - learning_rate * param.grad\n",
    "            # param.data = self.position[name] + learning_rate * param.grad\n",
    "            \n",
    "    def evaluate_test(self, dataloader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def evaluate_train(self, dataloader, criterion):\n",
    "        \"\"\"Calcula o erro (perda) e a acurácia da partícula utilizando o otimizador Adam.\"\"\"\n",
    "        self.model.train()  # Colocar o modelo em modo de treinamento\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            # Zerar gradientes acumulados\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(images)\n",
    "            \n",
    "            # Cálculo do erro (loss)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass (propagação do gradiente)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Atualizar os pesos usando Adam\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Acumular o erro total\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Cálculo da acurácia\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Obter predições (classe com maior probabilidade)\n",
    "            total += labels.size(0)                    # Número total de amostras\n",
    "            correct += (predicted == labels).sum().item()  # Número de predições corretas\n",
    "        \n",
    "        # Cálculo da perda média e acurácia\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total  # Acurácia = (predições corretas) / (total de amostras)\n",
    "\n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f610bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)    \n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size = 10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=10, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=10, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec85409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os hiperparâmetros do PSO e do Adam\n",
    "pop_size = 10\n",
    "num_epochs = 30\n",
    "#inertia = 0.9\n",
    "c1, c2 = 0.8, 0.9\n",
    "learning_rate = 0.0001\n",
    "beta1, beta2 = 0.9, 0.999\n",
    "epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0d06b",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafe9c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Validation Loss: 1.2334, Validation Accuracy: 0.5371\n",
      "Epoch 2/30, Validation Loss: 0.9779, Validation Accuracy: 0.6552\n",
      "Epoch 3/30, Validation Loss: 0.7831, Validation Accuracy: 0.7278\n",
      "Epoch 4/30, Validation Loss: 0.6650, Validation Accuracy: 0.7644\n",
      "Epoch 5/30, Validation Loss: 0.6301, Validation Accuracy: 0.7882\n",
      "Epoch 6/30, Validation Loss: 0.5787, Validation Accuracy: 0.8028\n",
      "Epoch 7/30, Validation Loss: 0.5933, Validation Accuracy: 0.8043\n",
      "Epoch 8/30, Validation Loss: 0.5424, Validation Accuracy: 0.8199\n",
      "Epoch 9/30, Validation Loss: 0.5468, Validation Accuracy: 0.8226\n",
      "Epoch 10/30, Validation Loss: 0.5662, Validation Accuracy: 0.8274\n",
      "Epoch 11/30, Validation Loss: 0.5709, Validation Accuracy: 0.8267\n",
      "Epoch 12/30, Validation Loss: 0.5685, Validation Accuracy: 0.8335\n",
      "Epoch 13/30, Validation Loss: 0.5792, Validation Accuracy: 0.8371\n",
      "Epoch 14/30, Validation Loss: 0.5805, Validation Accuracy: 0.8400\n",
      "Epoch 15/30, Validation Loss: 0.7303, Validation Accuracy: 0.8212\n",
      "Epoch 16/30, Validation Loss: 0.6297, Validation Accuracy: 0.8383\n",
      "Epoch 17/30, Validation Loss: 0.6552, Validation Accuracy: 0.8350\n",
      "Epoch 18/30, Validation Loss: 0.6501, Validation Accuracy: 0.8402\n",
      "Epoch 19/30, Validation Loss: 0.6288, Validation Accuracy: 0.8410\n",
      "Epoch 20/30, Validation Loss: 0.6727, Validation Accuracy: 0.8383\n",
      "Epoch 21/30, Validation Loss: 0.6647, Validation Accuracy: 0.8411\n",
      "Epoch 22/30, Validation Loss: 0.6861, Validation Accuracy: 0.8368\n",
      "Epoch 23/30, Validation Loss: 0.6620, Validation Accuracy: 0.8481\n",
      "Epoch 24/30, Validation Loss: 0.7149, Validation Accuracy: 0.8377\n",
      "Epoch 25/30, Validation Loss: 0.7028, Validation Accuracy: 0.8405\n",
      "Epoch 26/30, Validation Loss: 0.6661, Validation Accuracy: 0.8448\n",
      "Epoch 27/30, Validation Loss: 0.6767, Validation Accuracy: 0.8377\n",
      "Epoch 28/30, Validation Loss: 0.7311, Validation Accuracy: 0.8403\n",
      "Epoch 29/30, Validation Loss: 0.7006, Validation Accuracy: 0.8428\n",
      "Epoch 30/30, Validation Loss: 0.7132, Validation Accuracy: 0.8440\n",
      "Treinamento completo.\n",
      "Melhor pontuação de g-best: 0.05085213210902956\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Particle' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelhor pontuação de g-best:\u001b[39m\u001b[38;5;124m\"\u001b[39m, global_best_score)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Avaliação final no conjunto de teste\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m best_particle\u001b[38;5;241m.\u001b[39mevaluate(testloader, criterion)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvaliação final no conjunto de teste - Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Particle' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'alexnet'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    #Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdae07b",
   "metadata": {},
   "source": [
    "## MobileNet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8f7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Validation Loss: 1.4057, Validation Accuracy: 0.4832\n",
      "Epoch 2/30, Validation Loss: 1.1974, Validation Accuracy: 0.5645\n",
      "Epoch 3/30, Validation Loss: 1.0256, Validation Accuracy: 0.6350\n",
      "Epoch 4/30, Validation Loss: 0.9496, Validation Accuracy: 0.6673\n",
      "Epoch 5/30, Validation Loss: 0.8645, Validation Accuracy: 0.6997\n",
      "Epoch 6/30, Validation Loss: 0.8127, Validation Accuracy: 0.7169\n",
      "Epoch 7/30, Validation Loss: 0.7588, Validation Accuracy: 0.7374\n",
      "Epoch 8/30, Validation Loss: 0.7342, Validation Accuracy: 0.7513\n",
      "Epoch 9/30, Validation Loss: 0.7248, Validation Accuracy: 0.7566\n",
      "Epoch 10/30, Validation Loss: 0.7331, Validation Accuracy: 0.7572\n",
      "Epoch 11/30, Validation Loss: 0.7363, Validation Accuracy: 0.7625\n",
      "Epoch 12/30, Validation Loss: 0.7486, Validation Accuracy: 0.7666\n",
      "Epoch 13/30, Validation Loss: 0.7707, Validation Accuracy: 0.7656\n",
      "Epoch 14/30, Validation Loss: 0.8066, Validation Accuracy: 0.7657\n",
      "Epoch 15/30, Validation Loss: 0.8348, Validation Accuracy: 0.7631\n",
      "Epoch 16/30, Validation Loss: 0.8586, Validation Accuracy: 0.7704\n",
      "Epoch 17/30, Validation Loss: 0.8694, Validation Accuracy: 0.7721\n",
      "Epoch 18/30, Validation Loss: 0.8820, Validation Accuracy: 0.7772\n",
      "Epoch 19/30, Validation Loss: 0.9230, Validation Accuracy: 0.7707\n",
      "Epoch 20/30, Validation Loss: 0.9752, Validation Accuracy: 0.7670\n",
      "Epoch 21/30, Validation Loss: 0.9587, Validation Accuracy: 0.7717\n",
      "Epoch 22/30, Validation Loss: 0.9480, Validation Accuracy: 0.7698\n",
      "Epoch 23/30, Validation Loss: 0.9622, Validation Accuracy: 0.7751\n",
      "Epoch 24/30, Validation Loss: 0.9578, Validation Accuracy: 0.7802\n",
      "Epoch 25/30, Validation Loss: 0.9968, Validation Accuracy: 0.7808\n",
      "Epoch 26/30, Validation Loss: 0.9950, Validation Accuracy: 0.7770\n",
      "Epoch 27/30, Validation Loss: 1.0195, Validation Accuracy: 0.7707\n",
      "Epoch 28/30, Validation Loss: 1.0366, Validation Accuracy: 0.7735\n",
      "Epoch 29/30, Validation Loss: 1.0662, Validation Accuracy: 0.7733\n",
      "Epoch 30/30, Validation Loss: 1.0700, Validation Accuracy: 0.7759\n",
      "Treinamento completo.\n",
      "Melhor pontuação de g-best: 0.05479874104544844\n",
      "Avaliação final no conjunto de teste - Loss: 1.0700, Accuracy: 0.7759\n"
     ]
    }
   ],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'mobilenet_v2'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cd33a",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a0ed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Validation Loss: 1.0255, Validation Accuracy: 0.6310\n",
      "Epoch 2/30, Validation Loss: 0.8227, Validation Accuracy: 0.7077\n",
      "Epoch 3/30, Validation Loss: 0.6549, Validation Accuracy: 0.7744\n",
      "Epoch 4/30, Validation Loss: 0.7317, Validation Accuracy: 0.7588\n",
      "Epoch 5/30, Validation Loss: 0.7327, Validation Accuracy: 0.7629\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m particle\u001b[38;5;241m.\u001b[39mpso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Avaliar a partícula e atualizar o local best\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m particle\u001b[38;5;241m.\u001b[39mevaluate_train(trainloader, criterion)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m particle\u001b[38;5;241m.\u001b[39mbest_score:\n\u001b[0;32m     32\u001b[0m     particle\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m val_loss\n",
      "Cell \u001b[1;32mIn[2], line 107\u001b[0m, in \u001b[0;36mParticle.evaluate_train\u001b[1;34m(self, dataloader, criterion)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Acumular o erro total\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Cálculo da acurácia\u001b[39;00m\n\u001b[0;32m    110\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Obter predições (classe com maior probabilidade)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'resnet18'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df543a",
   "metadata": {},
   "source": [
    "## SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ff8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'squeezenet'  # escolha 'alexnet', 'vgg11', 'resnet18', 'mobilenet_v2' ou 'squeezenet'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "\n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "\n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "\n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c4434",
   "metadata": {},
   "source": [
    "## VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df04a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo\n",
    "architecture = 'vgg11'  # escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "model = select_model(architecture)\n",
    "\n",
    "# Inicializar as partículas (modelos)\n",
    "particles = [Particle(model, device) for _ in range(pop_size)]\n",
    "\n",
    "global_best_model = copy.deepcopy(particles[0].model)\n",
    "global_best_score = float('inf')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inicializar m e v para Adam\n",
    "m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
    "\n",
    "# Loop de treinamento do PSO\n",
    "for epoch in range(num_epochs):\n",
    "    inertia = 0.9 - ((0.9-0.4)/num_epochs)*epoch\n",
    "    for particle in particles:\n",
    "        # Colocar o modelo em modo de treinamento\n",
    "        particle.model.train()\n",
    "        \n",
    "        particle.optimizer.zero_grad()\n",
    "\n",
    "        # Treinar a partícula (atualização de posição)\n",
    "        particle.pso_sgd(global_best_model, inertia, c1, c2, learning_rate, beta1, beta2, epsilon, m, v, epoch + 1)\n",
    "        \n",
    "        # Avaliar a partícula e atualizar o local best\n",
    "        val_loss, val_accuracy = particle.evaluate_train(trainloader, criterion)\n",
    "        \n",
    "        if val_loss < particle.best_score:\n",
    "            particle.best_score = val_loss\n",
    "            particle.best_model = copy.deepcopy(particle.model)\n",
    "\n",
    "    # Determinar e atualizar o g-best (modelo global)\n",
    "    best_particle = min(particles, key=lambda p: p.best_score)\n",
    "    if best_particle.best_score < global_best_score:\n",
    "        global_best_score = best_particle.best_score\n",
    "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
    "\n",
    "    # Avaliar e imprimir a cada época\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"Treinamento completo.\")\n",
    "print(\"Melhor pontuação de g-best:\", global_best_score)\n",
    "\n",
    "# Avaliação final no conjunto de teste\n",
    "test_loss, test_accuracy = best_particle.evaluate_test(testloader, criterion)\n",
    "print(f'Avaliação final no conjunto de teste - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b72b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

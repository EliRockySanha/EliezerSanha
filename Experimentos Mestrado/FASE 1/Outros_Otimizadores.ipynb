{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25846b15",
   "metadata": {
    "id": "25846b15"
   },
   "source": [
    "# Treinamento Normal Sem PSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb1b67",
   "metadata": {
    "id": "99bb1b67"
   },
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad765059",
   "metadata": {
    "id": "ad765059",
    "outputId": "234d2edd-48d1-44a9-d42e-fa79fc399a1f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11' ou 'resnet18'\")\n",
    "    return model.to(device)\n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size = 10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Função para treinamento\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        val_loss, val_accuracy = evaluate_model(model, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    print('Treinamento concluído.')\n",
    "    return model\n",
    "\n",
    "# Função para avaliação\n",
    "def evaluate_model(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Definir arquitetura e otimizador\n",
    "architecture = 'alexnet'  # Escolha entre 'alexnet', 'vgg11' ou 'resnet18'\n",
    "optimizer_choice = 'Adam'  # Escolha entre 'AdaGrad', 'RMSProp' ou 'Adam'\n",
    "\n",
    "model = select_model(architecture)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Selecionar o otimizador\n",
    "if optimizer_choice == 'AdaGrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "elif optimizer_choice == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "elif optimizer_choice == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "else:\n",
    "    raise ValueError(\"Otimizador não suportado: escolha 'AdaGrad', 'RMSProp' ou 'Adam'\")\n",
    "\n",
    "# Treinar o modelo\n",
    "num_epochs = 30\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Avaliação final\n",
    "final_loss, final_accuracy = evaluate_model(trained_model, criterion)\n",
    "print(f'Avaliação final - Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "torch.save(trained_model.state_dict(), f'trained_model_{architecture}_{optimizer_choice}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75bcb49",
   "metadata": {
    "id": "f75bcb49"
   },
   "source": [
    "## VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440553d4",
   "metadata": {
    "id": "440553d4",
    "outputId": "ba4ea28c-57f7-4e19-9dee-dbc3583765bf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11' ou 'resnet18'\")\n",
    "    return model.to(device)\n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size = 10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Função para treinamento\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        val_loss, val_accuracy = evaluate_model(model, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    print('Treinamento concluído.')\n",
    "    return model\n",
    "\n",
    "# Função para avaliação\n",
    "def evaluate_model(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Definir arquitetura e otimizador\n",
    "architecture = 'vgg11'  # Escolha entre 'alexnet', 'vgg11' ou 'resnet18'\n",
    "optimizer_choice = 'Adam'  # Escolha entre 'AdaGrad', 'RMSProp' ou 'Adam'\n",
    "\n",
    "model = select_model(architecture)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Selecionar o otimizador\n",
    "if optimizer_choice == 'AdaGrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "elif optimizer_choice == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "elif optimizer_choice == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "else:\n",
    "    raise ValueError(\"Otimizador não suportado: escolha 'AdaGrad', 'RMSProp' ou 'Adam'\")\n",
    "\n",
    "# Treinar o modelo\n",
    "num_epochs = 30\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Avaliação final\n",
    "final_loss, final_accuracy = evaluate_model(trained_model, criterion)\n",
    "print(f'Avaliação final - Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "torch.save(trained_model.state_dict(), f'trained_model_{architecture}_{optimizer_choice}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924c930",
   "metadata": {
    "id": "0924c930"
   },
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb9d9a",
   "metadata": {
    "id": "06fb9d9a",
    "outputId": "44e1793c-570e-473f-8f65-adf5e88a6a91"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11' ou 'resnet18'\")\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size =10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Função para treinamento\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        val_loss, val_accuracy = evaluate_model(model, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    print('Treinamento concluído.')\n",
    "    return model\n",
    "\n",
    "# Função para avaliação\n",
    "def evaluate_model(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Definir arquitetura e otimizador\n",
    "architecture = 'resnet18'  # Escolha entre 'alexnet', 'vgg11' ou 'resnet18'\n",
    "optimizer_choice = 'Adam'  # Escolha entre 'AdaGrad', 'RMSProp' ou 'Adam'\n",
    "\n",
    "model = select_model(architecture)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Selecionar o otimizador\n",
    "if optimizer_choice == 'AdaGrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "elif optimizer_choice == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "elif optimizer_choice == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "else:\n",
    "    raise ValueError(\"Otimizador não suportado: escolha 'AdaGrad', 'RMSProp' ou 'Adam'\")\n",
    "\n",
    "# Treinar o modelo\n",
    "num_epochs = 30\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Avaliação final\n",
    "final_loss, final_accuracy = evaluate_model(trained_model, criterion)\n",
    "print(f'Avaliação final - Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "torch.save(trained_model.state_dict(), f'trained_model_{architecture}_{optimizer_choice}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc6204",
   "metadata": {
    "id": "f2fc6204"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecc33022",
   "metadata": {
    "id": "ecc33022"
   },
   "source": [
    "## MobileNet_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a12b79",
   "metadata": {
    "id": "54a12b79",
    "outputId": "d54135cb-8f9e-46aa-e80d-45fbe51f325b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    elif architecture == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\")\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size = 10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Função para treinamento\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        val_loss, val_accuracy = evaluate_model(model, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    print('Treinamento concluído.')\n",
    "    return model\n",
    "\n",
    "# Função para avaliação\n",
    "def evaluate_model(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Definir arquitetura e otimizador\n",
    "architecture = 'mobilenet_v2'  # Pode ser 'alexnet', 'vgg11', 'resnet18' ou 'mobilenet_v2'\n",
    "optimizer_choice = 'Adam'  # Escolha entre 'AdaGrad', 'RMSProp' ou 'Adam'\n",
    "\n",
    "model = select_model(architecture)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Selecionar o otimizador\n",
    "if optimizer_choice == 'AdaGrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "elif optimizer_choice == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "elif optimizer_choice == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "else:\n",
    "    raise ValueError(\"Otimizador não suportado: escolha 'AdaGrad', 'RMSProp' ou 'Adam'\")\n",
    "\n",
    "# Treinar o modelo\n",
    "num_epochs = 30\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Avaliação final\n",
    "final_loss, final_accuracy = evaluate_model(trained_model, criterion)\n",
    "print(f'Avaliação final - Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "torch.save(trained_model.state_dict(), f'trained_model_{architecture}_{optimizer_choice}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zB8QPi88KZPK",
   "metadata": {
    "id": "zB8QPi88KZPK"
   },
   "source": [
    "## SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hSDHfJ1-KTXp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "executionInfo": {
     "elapsed": 728817,
     "status": "error",
     "timestamp": 1729902835337,
     "user": {
      "displayName": "Eliezer Sanhá",
      "userId": "07034799936810465209"
     },
     "user_tz": 180
    },
    "id": "hSDHfJ1-KTXp",
    "outputId": "b915109e-625f-4ba2-970b-d62b9140702e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Função para criar um subconjunto dos dados\n",
    "def create_subset(dataset, subset_size):\n",
    "    indices = list(range(len(dataset)))\n",
    "    subset_indices = random.sample(indices, subset_size)\n",
    "    return Subset(dataset, subset_indices)\n",
    "\n",
    "\n",
    "# Função para selecionar o modelo sem pré-treinamento\n",
    "def select_model(architecture):\n",
    "    if architecture == 'alexnet':\n",
    "        model = models.alexnet(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'vgg11':\n",
    "        model = models.vgg11(weights=None)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
    "    elif architecture == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    elif architecture == 'squeezenet':\n",
    "        model = models.squeezenet1_1(weights=None)\n",
    "        model.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))\n",
    "        model.num_classes = 10\n",
    "    else:\n",
    "        raise ValueError(\"Arquitetura não suportada: escolha 'alexnet', 'vgg11', 'resnet18' ou 'squeezenet'\")\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "# Transformações de dados com normalizações para modelos pré-treinados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Reduzir a quantidade de dados usados\n",
    "train_subset_size = 50000  # Número ainda mais reduzido de exemplos de treino\n",
    "test_subset_size = 10000    # Número ainda mais reduzido de exemplos de teste\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_subset = create_subset(trainset, train_subset_size)\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_subset = create_subset(testset, test_subset_size)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)  # Reduzir o batch_size\n",
    "\n",
    "# Carregar o conjunto de dados CIFAR-10\n",
    "#trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Criar DataLoader\n",
    "#trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Função para treinamento\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        val_loss, val_accuracy = evaluate_model(model, criterion)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    print('Treinamento concluído.')\n",
    "    return model\n",
    "\n",
    "# Função para avaliação\n",
    "def evaluate_model(model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Definir arquitetura e otimizador\n",
    "architecture = 'squeezenet'  # Escolha entre 'alexnet', 'vgg11', 'resnet18' ou 'squeezenet'\"\n",
    "optimizer_choice = 'Adam'  # Escolha entre 'AdaGrad', 'RMSProp' ou 'Adam'\n",
    "\n",
    "model = select_model(architecture)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Selecionar o otimizador\n",
    "if optimizer_choice == 'AdaGrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "elif optimizer_choice == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "elif optimizer_choice == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "else:\n",
    "    raise ValueError(\"Otimizador não suportado: escolha 'AdaGrad', 'RMSProp' ou 'Adam'\")\n",
    "\n",
    "# Treinar o modelo\n",
    "num_epochs = 30\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Avaliação final\n",
    "final_loss, final_accuracy = evaluate_model(trained_model, criterion)\n",
    "print(f'Avaliação final - Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "torch.save(trained_model.state_dict(), f'trained_model_{architecture}_{optimizer_choice}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5781dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
